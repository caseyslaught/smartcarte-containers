{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccefd33-447b-4290-8b26-af608cc346bf",
   "metadata": {},
   "source": [
    "## Build U-NET++ semantic segmentation model using PyTorch ðŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182cec5-049f-428f-9428-c170d2fb9e45",
   "metadata": {},
   "source": [
    "### Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841da7f0-583e-4769-8fb2-89c6296c792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from common.constants import NODATA_FLOAT32\n",
    "\n",
    "\n",
    "torch.manual_seed(666)\n",
    "\n",
    "\n",
    "class LabeledS2Dataset(Dataset):\n",
    "    def __init__(self, root_dir, sub_dir):\n",
    "        self.data_dir = f'{root_dir}/{sub_dir}'\n",
    "        self.image_paths = glob.glob(f'{self.data_dir}/images/*.tif')\n",
    "        self.label_paths = glob.glob(f'{self.data_dir}/labels/*.tif')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_path = self.image_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read()\n",
    "            # image[image == NODATA_FLOAT32] = -0.01\n",
    "            # handle nodata here...\n",
    "            image = torch.from_numpy(image)\n",
    "\n",
    "        with rasterio.open(label_path) as src:\n",
    "            label = src.read()\n",
    "            # label[label == 0] = 0\n",
    "            label = torch.from_numpy(label).long()\n",
    "\n",
    "        return image, label    \n",
    "    \n",
    "\n",
    "train_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=0, shuffle=True)\n",
    "\n",
    "test_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, num_workers=0, shuffle=True)\n",
    "\n",
    "val_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='val')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, num_workers=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f07ff2-f90c-4e78-9f3e-a2d9a19ff9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.utils as smp_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# make sure this is in sync with create patches\n",
    "CLASSES = {\n",
    "    'unclassified': 0,\n",
    "    'agriculture': 10,\n",
    "    'bare_dark': 5,\n",
    "    'bare_light': 4,\n",
    "    'built': 6,\n",
    "    'burn': 9,\n",
    "    'cloud': 1,\n",
    "    'flooded_vegetation': 3,\n",
    "    'grass_dry': 12,\n",
    "    'grass_verdant': 11,\n",
    "    'shrubs': 8,\n",
    "    'trees': 7,\n",
    "    'water': 2\n",
    "}\n",
    "\n",
    "CLASS_NAMES = list(CLASSES.keys())\n",
    "CLASS_INDEXES = list(CLASSES.values())\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name='resnet18', \n",
    "    encoder_depth=5, \n",
    "    encoder_weights='imagenet', \n",
    "    decoder_use_batchnorm=True, \n",
    "    decoder_channels=(256, 128, 64, 32, 16), \n",
    "    decoder_attention_type=None, \n",
    "    in_channels=4, \n",
    "    classes=len(CLASS_NAMES), \n",
    "    activation=None, \n",
    "    aux_params=None\n",
    ")\n",
    "\n",
    "\n",
    "loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "loss.__name__ = 'Dice_loss'\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "metrics = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb83e26-c863-4037-ae1b-9245f16327eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp_utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics= metrics,\n",
    "    optimizer=optimizer,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "test_epoch = smp_utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e241234-3906-4d89-bca8-a1ecc667b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "\n",
    "for i in range(0, 1):\n",
    "    train_logs = train_epoch.run(train_dataloader)\n",
    "    test_logs = test_epoch.run(test_dataloader)\n",
    "    torch.save(model, './best_model.pth')\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04433329-9964-412b-9954-947d5d2fbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = torch.load('./best_model.pth')\n",
    "\n",
    "val_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "logs = val_epoch.run(val_dataloader)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266cd3c-3949-4cd2-a359-499ab9224b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "count = 1\n",
    "\n",
    "fig, rows = plt.subplots(count, 3, figsize=(16, 20))\n",
    "    \n",
    "\n",
    "for i in range(count):\n",
    "            \n",
    "    image, labels = val_dataset[i]   \n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.tensor(image)\n",
    "\n",
    "    prediction = best_model.predict(image)\n",
    "    \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    probabilities = softmax(prediction)\n",
    "    \n",
    "    prediction = torch.argmax(probabilities, dim=1).squeeze(1)\n",
    "    prediction = (prediction.squeeze().cpu().numpy().round())\n",
    "    prediction = np.ma.array(prediction, mask=(prediction==0))\n",
    "\n",
    "    labels = labels.squeeze().numpy()\n",
    "    labels = np.ma.array(labels, mask=(labels==0))\n",
    "    \n",
    "    \n",
    "    print(np.unique(labels))\n",
    "    print(np.unique(prediction))\n",
    "    \n",
    "    row = rows[i]\n",
    "    \n",
    "    nir_data = image.squeeze()[3].numpy()\n",
    "    nir_data = np.ma.array(nir_data, mask=(nir_data==NODATA_FLOAT32))\n",
    "\n",
    "    row[0].imshow(nir_data)\n",
    "    row[0].set_title('Image (B08)')\n",
    "    \n",
    "    row[1].imshow(labels, vmin=0, vmax=13)\n",
    "    row[1].set_title('Truth')\n",
    "    \n",
    "    row[2].imshow(prediction, vmin=0, vmax=13)\n",
    "    row[2].set_title('Prediction')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
