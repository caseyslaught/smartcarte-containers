{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "labelbox_dir = \"./data/labelbox\"\n",
    "labelbox_clouds_dir = f'{labelbox_dir}/clouds'\n",
    "labelbox_clouds_rgb_dir = f'{labelbox_clouds_dir}/rgb'\n",
    "labelbox_clouds_labels_dir = f'{labelbox_clouds_dir}/labels'\n",
    "labelbox_clouds_source_dir = f'{labelbox_clouds_dir}/source'\n",
    "\n",
    "labelbox_clouds_temp_dir = f'{labelbox_clouds_dir}/temp'\n",
    "\n",
    "os.makedirs(labelbox_clouds_labels_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_rgb_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_source_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_temp_dir, exist_ok=True)\n",
    "\n",
    "state_path = \"./data/labelbox/clouds/uploadState\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chips from bounding box and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "\n",
    "from common.constants import NODATA_BYTE, NODATA_FLOAT32, RES, S2_BANDS_TIFF_ORDER\n",
    "import common.utilities.download as download\n",
    "import common.utilities.imagery as imagery\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "\n",
    "def create_chips_from_bbox(bbox, start_date, end_date):\n",
    "    \n",
    "    collection_path = f'{labelbox_clouds_temp_dir}/collection.json'\n",
    "    collection = download.get_collection(start_date, end_date, bbox, collection_path, max_cloud_cover=100, max_tile_count=1, min_tile_count=1)\n",
    "    original_scenes = download.download_collection(collection, bbox, S2_BANDS_TIFF_ORDER, labelbox_clouds_temp_dir, RES)\n",
    "\n",
    "    for scene in original_scenes:\n",
    "        print(f'\\tpatchifying... {scene}')\n",
    "        \n",
    "        stack_path = original_scenes[scene][\"stack_original_tif_path\"]\n",
    "        with rasterio.open(stack_path) as src:\n",
    "            if src.width < 512 or src.height < 512:\n",
    "                print(f'\\t\\tskipping... {scene}')\n",
    "                continue\n",
    "\n",
    "        bbox_str = ''.join([str(round(coord, 2)) for coord in bbox]).replace('.', '')\n",
    "            \n",
    "        with rasterio.open(stack_path) as src:\n",
    "            stack_data = src.read().transpose((1, 2, 0))\n",
    "            transform = src.transform\n",
    "\n",
    "            source_patches = patchify(stack_data, (PATCH_SIZE, PATCH_SIZE, stack_data.shape[2]), step=PATCH_SIZE)\n",
    "            \n",
    "            for irow in range(source_patches.shape[0]):\n",
    "                for icol in range(source_patches.shape[1]):\n",
    "                    source_data = source_patches[irow, icol, 0, :, :, :]\n",
    "                    \n",
    "                    rgb_data = source_data[:, :, [2, 1, 0]]\n",
    "                    rgb_data_norm = (rgb_data * 254).astype(np.uint8)\n",
    "                    rgb_data_norm[rgb_data_norm > 254] = 254\n",
    "        \n",
    "                    rgb_path = f'{labelbox_clouds_rgb_dir}/{scene}_{bbox_str}_{irow}_{icol}.tif'\n",
    "                    source_path = f'{labelbox_clouds_source_dir}/{scene}_{bbox_str}_{irow}_{icol}.tif'\n",
    "                    \n",
    "                    x_min, y_min = rasterio.transform.xy(transform, PATCH_SIZE*(irow+1), PATCH_SIZE*icol)\n",
    "                    x_max, y_max = rasterio.transform.xy(transform, PATCH_SIZE*irow, PATCH_SIZE*(icol+1))             \n",
    "                    chip_bbox = [x_min, y_min, x_max, y_max]\n",
    "                                        \n",
    "                    imagery.write_array_to_tif(source_data, source_path, chip_bbox, dtype=np.float32, nodata=NODATA_FLOAT32)\n",
    "                    imagery.write_array_to_tif(rgb_data_norm, rgb_path, chip_bbox, dtype=np.uint8, nodata=NODATA_BYTE, is_cog=True)                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.constants as constants\n",
    "import common.aws.s3 as s3_utils\n",
    "\n",
    "\n",
    "def save_rgb_chip_to_s3(rgb_path):\n",
    "    file_name = rgb_path.split('/')[-1]    \n",
    "    object_key = f'training/clouds/{file_name}'\n",
    "    href = f'https://data.smartcarte.earth/{object_key}'\n",
    "    s3_utils.put_item(rgb_path, constants.S3_DATA_BUCKET, object_key)\n",
    "    return href\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from labelbox import Client, Dataset, DataRow\n",
    "import glob\n",
    "import os\n",
    "import shelve\n",
    "\n",
    "\n",
    "try:\n",
    "    from common.sagemaker_env import LABELBOX_API_KEY\n",
    "except: \n",
    "    LABELBOX_API_KEY = os.environ['LABELBOX_API_KEY']\n",
    "    \n",
    "CLOUD_PROJECT_ID = \"cleamnf3q398707ug5s2z4rp6\"\n",
    "\n",
    "\n",
    "client = Client(api_key=LABELBOX_API_KEY)\n",
    "project = client.get_project(CLOUD_PROJECT_ID)\n",
    "\n",
    "\n",
    "def create_labelbox_dataset(prefix=\"\"):\n",
    "    \n",
    "    today = datetime.datetime.today().strftime('%Y%m%d_%H%M')\n",
    "    clouds_dataset_name = f\"Clouds {prefix} {today}\"\n",
    "    \n",
    "    clouds_dataset = client.get_datasets(where=(Dataset.name==clouds_dataset_name)).get_one()\n",
    "    if clouds_dataset is not None:\n",
    "        raise ValueError(\"cloud dataset already exists; wait a minute\")        \n",
    "\n",
    "    rgb_paths = glob.glob(f'{labelbox_clouds_rgb_dir}/*[0-9].tif')\n",
    "    print(f'{len(rgb_paths)} total chips')\n",
    "        \n",
    "    with shelve.open(state_path) as upload_state:\n",
    "        \n",
    "        payload = []\n",
    "        for rgb_path in rgb_paths:\n",
    "            chip_id = rgb_path.split('/')[-1].replace('.tif', '')\n",
    "            chip_state = upload_state.get(chip_id)\n",
    "            \n",
    "            if chip_state and chip_state.get('uploaded_to_labelbox', False):\n",
    "                continue\n",
    "            \n",
    "            s3_href = save_rgb_chip_to_s3(rgb_path)\n",
    "            \n",
    "            payload.append({\n",
    "                \"chip_id\": chip_id,\n",
    "                \"min_zoom\": 10,\n",
    "                \"max_zoom\": 14,\n",
    "                \"tile_layer_url\": s3_href\n",
    "            })\n",
    "\n",
    "            upload_state[chip_id] = {\n",
    "                'rgb_cog_href': s3_href,\n",
    "                'uploaded_to_s3': True,\n",
    "                'uploaded_to_labelbox': False\n",
    "            }\n",
    "                    \n",
    "        if len(payload) > 0:\n",
    "            print(f'{len(payload)} chips to add to Labelbox')\n",
    "\n",
    "            clouds_dataset = client.create_dataset(name=clouds_dataset_name)\n",
    "            datarow_payload = [{DataRow.row_data: row} for row in payload]\n",
    "            task = clouds_dataset.create_data_rows(datarow_payload)\n",
    "            task.wait_till_done()\n",
    "\n",
    "            for row in payload:\n",
    "                chip_id = row[\"chip_id\"]\n",
    "                upload_state[chip_id] = {\n",
    "                    'rgb_cog_href': s3_href,\n",
    "                    'uploaded_to_s3': True,\n",
    "                    'uploaded_to_labelbox': True\n",
    "                }\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new chips üêøÔ∏èüêøÔ∏èüêøÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_new_chips(bbox, region_name, dates):\n",
    "    for date in dates:\n",
    "        start_date, end_date = date[0], date[1]\n",
    "        create_chips_from_bbox(bbox, start_date, end_date)\n",
    "        \n",
    "    create_labelbox_dataset(prefix=region_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "dates = [\n",
    "    (dt.datetime(2019, 1, 1), dt.datetime(2019, 2, 1)),\n",
    "    (dt.datetime(2020, 3, 1), dt.datetime(2020, 4, 1)),\n",
    "    (dt.datetime(2021, 6, 1), dt.datetime(2021, 7, 1)),\n",
    "    (dt.datetime(2022, 9, 1), dt.datetime(2022, 10, 1)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boma National Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'WM': 1, 'XM': 1, 'XN': 1, 'WN': 1}\n",
      "\tdownloading... S2A_36NWM_20190105_0_L2A\n",
      "\tdownloading... S2A_36NXM_20190115_0_L2A\n",
      "\tdownloading... S2A_36NXN_20190115_0_L2A\n",
      "\tdownloading... S2A_36NWN_20190115_0_L2A\n",
      "\tpatchifying... S2A_36NWM_20190105_0_L2A\n",
      "\tpatchifying... S2A_36NXM_20190115_0_L2A\n",
      "\tpatchifying... S2A_36NXN_20190115_0_L2A\n",
      "\tpatchifying... S2A_36NWN_20190115_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'WN': 1, 'WM': 1, 'XN': 1, 'XM': 1}\n",
      "\tdownloading... S2B_36NWN_20200325_0_L2A\n",
      "\tdownloading... S2B_36NWM_20200325_0_L2A\n",
      "\tdownloading... S2A_36NXN_20200310_0_L2A\n",
      "\tdownloading... S2B_36NXM_20200325_0_L2A\n",
      "\tpatchifying... S2B_36NWN_20200325_0_L2A\n",
      "\tpatchifying... S2B_36NWM_20200325_0_L2A\n",
      "\tpatchifying... S2A_36NXN_20200310_0_L2A\n",
      "\tpatchifying... S2B_36NXM_20200325_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'WM': 1, 'WN': 1, 'XN': 1, 'XM': 1}\n",
      "\tdownloading... S2B_36NWM_20210608_0_L2A\n",
      "\tdownloading... S2B_36NWN_20210608_0_L2A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m bbox_boma \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m33.884583\u001b[39m, \u001b[38;5;241m6.180003\u001b[39m, \u001b[38;5;241m34.083033\u001b[39m, \u001b[38;5;241m6.344253\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcreate_new_chips\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_boma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBoma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[175], line 4\u001b[0m, in \u001b[0;36mcreate_new_chips\u001b[0;34m(bbox, region_name, dates)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[1;32m      3\u001b[0m     start_date, end_date \u001b[38;5;241m=\u001b[39m date[\u001b[38;5;241m0\u001b[39m], date[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mcreate_chips_from_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m create_labelbox_dataset(prefix\u001b[38;5;241m=\u001b[39mregion_name)\n",
      "Cell \u001b[0;32mIn[172], line 21\u001b[0m, in \u001b[0;36mcreate_chips_from_bbox\u001b[0;34m(bbox, start_date, end_date)\u001b[0m\n\u001b[1;32m     19\u001b[0m collection_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabelbox_clouds_temp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/collection.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m collection \u001b[38;5;241m=\u001b[39m download\u001b[38;5;241m.\u001b[39mget_collection(start_date, end_date, bbox, collection_path, max_cloud_cover\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_tile_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_tile_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m original_scenes \u001b[38;5;241m=\u001b[39m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS2_BANDS_TIFF_ORDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelbox_clouds_temp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scene \u001b[38;5;129;01min\u001b[39;00m original_scenes:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mpatchifying... \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/src/common/utilities/download.py:194\u001b[0m, in \u001b[0;36mdownload_collection\u001b[0;34m(collection, bbox, bands, dst_dir, res)\u001b[0m\n\u001b[1;32m    191\u001b[0m s3_data \u001b[38;5;241m=\u001b[39m normalize_original_s2_array(s3_data)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# writing to item-EPSG first does not seem to help with alignment\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m \u001b[43mwrite_array_to_tif\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_bbox_utm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_epsg_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNODATA_FLOAT32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#write_array_to_tif(s3_data, band_path, overlap_bbox_ll, dtype=np.float32, epsg=4326, nodata=NODATA_FLOAT32, is_cog=False)\u001b[39;00m\n\u001b[1;32m    196\u001b[0m gdal\u001b[38;5;241m.\u001b[39mWarp(band_path, band_path, dstSRS\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m, xRes\u001b[38;5;241m=\u001b[39mres, yRes\u001b[38;5;241m=\u001b[39mres, outputBounds\u001b[38;5;241m=\u001b[39moverlap_bbox_ll)\n",
      "File \u001b[0;32m/home/src/common/utilities/imagery.py:276\u001b[0m, in \u001b[0;36mwrite_array_to_tif\u001b[0;34m(data, dst_path, bbox, dtype, epsg, nodata, is_cog, transform)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 band_data \u001b[38;5;241m=\u001b[39m band_data\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    274\u001b[0m                 band_data[mask] \u001b[38;5;241m=\u001b[39m nodata\n\u001b[0;32m--> 276\u001b[0m             dst\u001b[38;5;241m.\u001b[39mwrite(band_data, indexes\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_cog:\n\u001b[1;32m    279\u001b[0m     translate_options \u001b[38;5;241m=\u001b[39m gdal\u001b[38;5;241m.\u001b[39mTranslateOptions(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mrasterio/_base.pyx:395\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__exit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/var/lang/lib/python3.8/site-packages/rasterio/env.py:360\u001b[0m, in \u001b[0;36mNullContextManager.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_boma = [33.884583, 6.180003, 34.083033, 6.344253]\n",
    "create_new_chips(bbox_boma, \"Boma\", dates)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virunga National Park (Gorilla Sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20200123_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20200123_0_L2A\n",
      "\t34 total chips\n",
      "\t6 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_virunga_gorilla_sector = [ 29.397261, -1.464377, 29.497164, -1.392410]\n",
    "create_new_chips(bbox_virunga_gorilla_sector, \"Virunga Gorilla Sector\", dates)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
