{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "labelbox_dir = \"./data/labelbox\"\n",
    "labelbox_clouds_dir = f'{labelbox_dir}/clouds'\n",
    "labelbox_clouds_rgb_dir = f'{labelbox_clouds_dir}/rgb'\n",
    "labelbox_clouds_labels_dir = f'{labelbox_clouds_dir}/labels'\n",
    "labelbox_clouds_source_dir = f'{labelbox_clouds_dir}/source'\n",
    "\n",
    "labelbox_clouds_temp_dir = f'{labelbox_clouds_dir}/temp'\n",
    "\n",
    "os.makedirs(labelbox_clouds_labels_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_rgb_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_source_dir, exist_ok=True)\n",
    "os.makedirs(labelbox_clouds_temp_dir, exist_ok=True)\n",
    "\n",
    "state_path = \"./data/labelbox/clouds/uploadState\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chips from bounding box and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "\n",
    "from common.constants import NODATA_BYTE, NODATA_FLOAT32, RES, S2_BANDS_TIFF_ORDER\n",
    "import common.utilities.download as download\n",
    "import common.utilities.imagery as imagery\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "\n",
    "def create_chips_from_bbox(bbox, start_date, end_date):\n",
    "    \n",
    "    collection_path = f'{labelbox_clouds_temp_dir}/collection.json'\n",
    "    collection = download.get_collection(start_date, end_date, bbox, collection_path, max_cloud_cover=100, max_tile_count=1, min_tile_count=1)\n",
    "    original_scenes = download.download_collection(collection, bbox, S2_BANDS_TIFF_ORDER, labelbox_clouds_temp_dir, RES)\n",
    "\n",
    "    for scene in original_scenes:\n",
    "        print(f'\\tpatchifying... {scene}')\n",
    "        \n",
    "        stack_path = original_scenes[scene][\"stack_original_tif_path\"]\n",
    "        with rasterio.open(stack_path) as src:\n",
    "            if src.width < 512 or src.height < 512:\n",
    "                print(f'\\t\\tskipping... {scene}')\n",
    "                continue\n",
    "\n",
    "        bbox_str = ''.join([str(round(coord, 2)) for coord in bbox]).replace('.', '').replace('-', 'n')\n",
    "            \n",
    "        with rasterio.open(stack_path) as src:\n",
    "            stack_data = src.read().transpose((1, 2, 0))\n",
    "            transform = src.transform\n",
    "\n",
    "            source_patches = patchify(stack_data, (PATCH_SIZE, PATCH_SIZE, stack_data.shape[2]), step=PATCH_SIZE)\n",
    "            \n",
    "            for irow in range(source_patches.shape[0]):\n",
    "                for icol in range(source_patches.shape[1]):\n",
    "                    source_data = source_patches[irow, icol, 0, :, :, :]\n",
    "                    \n",
    "                    rgb_data = source_data[:, :, [2, 1, 0]]\n",
    "                    rgb_data_norm = (rgb_data * 254).astype(np.uint8)\n",
    "                    rgb_data_norm[rgb_data_norm > 254] = 254\n",
    "        \n",
    "                    rgb_path = f'{labelbox_clouds_rgb_dir}/{scene}_{bbox_str}_{irow}_{icol}.tif'\n",
    "                    source_path = f'{labelbox_clouds_source_dir}/{scene}_{bbox_str}_{irow}_{icol}.tif'\n",
    "                    \n",
    "                    x_min, y_min = rasterio.transform.xy(transform, PATCH_SIZE*(irow+1), PATCH_SIZE*icol)\n",
    "                    x_max, y_max = rasterio.transform.xy(transform, PATCH_SIZE*irow, PATCH_SIZE*(icol+1))             \n",
    "                    chip_bbox = [x_min, y_min, x_max, y_max]\n",
    "                                        \n",
    "                    imagery.write_array_to_tif(source_data, source_path, chip_bbox, dtype=np.float32, nodata=NODATA_FLOAT32)\n",
    "                    imagery.write_array_to_tif(rgb_data_norm, rgb_path, chip_bbox, dtype=np.uint8, nodata=NODATA_BYTE, is_cog=True)                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import common.constants as constants\n",
    "import common.aws.s3 as s3_utils\n",
    "\n",
    "\n",
    "def save_rgb_chip_to_s3(rgb_path):\n",
    "    file_name = rgb_path.split('/')[-1]    \n",
    "    object_key = f'training/clouds/rgb/{file_name}'\n",
    "    href = f'https://data.smartcarte.earth/{object_key}'\n",
    "    s3_utils.put_item(rgb_path, constants.S3_DATA_BUCKET, object_key)\n",
    "    return href\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from labelbox import Client, Dataset, DataRow\n",
    "import glob\n",
    "import os\n",
    "import shelve\n",
    "\n",
    "\n",
    "try:\n",
    "    from common.sagemaker_env import LABELBOX_API_KEY\n",
    "except: \n",
    "    LABELBOX_API_KEY = os.environ['LABELBOX_API_KEY']\n",
    "    \n",
    "CLOUD_PROJECT_ID = \"cleamnf3q398707ug5s2z4rp6\"\n",
    "\n",
    "\n",
    "client = Client(api_key=LABELBOX_API_KEY)\n",
    "project = client.get_project(CLOUD_PROJECT_ID)\n",
    "\n",
    "\n",
    "def create_labelbox_dataset(prefix=\"\"):\n",
    "    \n",
    "    today = datetime.datetime.today().strftime('%Y%m%d_%H%M')\n",
    "    clouds_dataset_name = f\"Clouds {prefix} {today}\"\n",
    "    \n",
    "    clouds_dataset = client.get_datasets(where=(Dataset.name==clouds_dataset_name)).get_one()\n",
    "    if clouds_dataset is not None:\n",
    "        raise ValueError(\"cloud dataset already exists; wait a minute\")        \n",
    "\n",
    "    rgb_paths = glob.glob(f'{labelbox_clouds_rgb_dir}/*[0-9].tif')\n",
    "    print(f'{len(rgb_paths)} total chips')\n",
    "        \n",
    "    with shelve.open(state_path) as upload_state:\n",
    "        \n",
    "        payload = []\n",
    "        for rgb_path in rgb_paths:\n",
    "            chip_id = rgb_path.split('/')[-1].replace('.tif', '')\n",
    "            chip_state = upload_state.get(chip_id)\n",
    "            \n",
    "            if chip_state and chip_state.get('uploaded_to_labelbox', False):\n",
    "                continue\n",
    "            \n",
    "            s3_href = save_rgb_chip_to_s3(rgb_path)\n",
    "            \n",
    "            payload.append({\n",
    "                \"chip_id\": chip_id,\n",
    "                \"min_zoom\": 10,\n",
    "                \"max_zoom\": 14,\n",
    "                \"tile_layer_url\": s3_href\n",
    "            })\n",
    "\n",
    "            upload_state[chip_id] = {\n",
    "                'rgb_cog_href': s3_href,\n",
    "                'uploaded_to_s3': True,\n",
    "                'uploaded_to_labelbox': False\n",
    "            }\n",
    "                    \n",
    "        if len(payload) > 0:\n",
    "            print(f'{len(payload)} chips to add to Labelbox')\n",
    "\n",
    "            clouds_dataset = client.create_dataset(name=clouds_dataset_name)\n",
    "            datarow_payload = [{DataRow.row_data: row} for row in payload]\n",
    "            task = clouds_dataset.create_data_rows(datarow_payload)\n",
    "            task.wait_till_done()\n",
    "\n",
    "            for row in payload:\n",
    "                chip_id = row[\"chip_id\"]\n",
    "                upload_state[chip_id] = {\n",
    "                    'rgb_cog_href': s3_href,\n",
    "                    'uploaded_to_s3': True,\n",
    "                    'uploaded_to_labelbox': True\n",
    "                }\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new chips üêøÔ∏èüêøÔ∏èüêøÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "def create_new_chips(bbox, region_name, dates):\n",
    "    for date in dates:\n",
    "        start_date, end_date = date[0], date[1]\n",
    "        create_chips_from_bbox(bbox, start_date, end_date)\n",
    "        \n",
    "    create_labelbox_dataset(prefix=region_name)\n",
    "    \n",
    "    \n",
    "def clean_up():\n",
    "    if os.path.exists(labelbox_clouds_temp_dir):\n",
    "        shutil.rmtree(labelbox_clouds_temp_dir)\n",
    "        os.makedirs(labelbox_clouds_temp_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "dates = [\n",
    "    (dt.datetime(2019, 1, 1), dt.datetime(2019, 2, 1)),\n",
    "    (dt.datetime(2020, 3, 1), dt.datetime(2020, 4, 1)),\n",
    "    (dt.datetime(2021, 6, 1), dt.datetime(2021, 7, 1)),\n",
    "    (dt.datetime(2022, 9, 1), dt.datetime(2022, 10, 1)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boma National Park üêò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'WN': 1}\n",
      "\tdownloading... S2A_36NWN_20190115_0_L2A\n",
      "\tpatchifying... S2A_36NWN_20190115_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'WN': 1}\n",
      "\tdownloading... S2B_36NWN_20200325_0_L2A\n",
      "\tpatchifying... S2B_36NWN_20200325_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'WN': 1}\n",
      "\tdownloading... S2B_36NWN_20210608_0_L2A\n",
      "\tpatchifying... S2B_36NWN_20210608_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'WN': 1}\n",
      "\tdownloading... S2A_36NWN_20220906_0_L2A\n",
      "\tpatchifying... S2A_36NWN_20220906_0_L2A\n",
      "60 total chips\n",
      "60 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_boma = [33.494145, 6.592713, 33.730720, 6.753140]\n",
    "create_new_chips(bbox_boma, \"Boma\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virunga National Park (Gorilla Sector) ü¶ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20190123_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20190123_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20200323_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20200323_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20210611_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20210611_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20220929_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20220929_0_L2A\n",
      "84 total chips\n",
      "24 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_virunga_gorilla_sector = [29.397261, -1.464377, 29.55281, -1.366300]\n",
    "create_new_chips(bbox_virunga_gorilla_sector, \"Virunga Gorilla Sector\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virunga National Park (Volcano Sector) üåã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20190123_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20190123_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20200323_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20200323_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20210611_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20210611_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20220929_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20220929_0_L2A\n",
      "196 total chips\n",
      "112 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_volcano = [29.037465, -1.445036, 29.364781, -1.217466]\n",
    "create_new_chips(bbox_volcano, \"Virunga Volcano Sector\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virunga Central Sector ü¶õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'QV': 1}\n",
      "\tdownloading... S2B_35MQV_20190123_0_L2A\n",
      "\tpatchifying... S2B_35MQV_20190123_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QV': 1}\n",
      "\tdownloading... S2A_35MQV_20200303_0_L2A\n",
      "\tpatchifying... S2A_35MQV_20200303_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QV': 1}\n",
      "\tdownloading... S2B_35MQV_20210611_0_L2A\n",
      "\tpatchifying... S2B_35MQV_20210611_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QV': 1}\n",
      "\tdownloading... S2A_35MQV_20220929_0_L2A\n",
      "\tpatchifying... S2A_35MQV_20220929_0_L2A\n",
      "324 total chips\n",
      "72 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_virunga_central_sector = [29.258226, -0.760528, 29.545592, -0.583160]\n",
    "create_new_chips(bbox_virunga_central_sector, \"Virunga Central Sector\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Goma üèôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20190123_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20190123_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20200323_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20200323_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2B_35MQU_20210611_0_L2A\n",
      "\tpatchifying... S2B_35MQU_20210611_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'QU': 1}\n",
      "\tdownloading... S2A_35MQU_20220929_0_L2A\n",
      "\tpatchifying... S2A_35MQU_20220929_0_L2A\n",
      "228 total chips\n",
      "32 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_goma = [29.084695, -1.708073, 29.310951, -1.605942]\n",
    "create_new_chips(bbox_goma, \"Goma\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zakouma National Park ü¶í"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/labelbox/clouds/temp/collection.json: {'CT': 1, 'CS': 1}\n",
      "\tdownloading... S2A_34PCT_20190123_1_L2A\n",
      "\tdownloading... S2A_34PCS_20190123_0_L2A\n",
      "\tpatchifying... S2A_34PCT_20190123_1_L2A\n",
      "\tpatchifying... S2A_34PCS_20190123_0_L2A\n",
      "\t\tskipping... S2A_34PCS_20190123_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'CT': 1, 'CS': 1}\n",
      "\tdownloading... S2B_34PCT_20200303_0_L2A\n",
      "\tdownloading... S2B_34PCS_20200323_0_L2A\n",
      "\tpatchifying... S2B_34PCT_20200303_0_L2A\n",
      "\tpatchifying... S2B_34PCS_20200323_0_L2A\n",
      "\t\tskipping... S2B_34PCS_20200323_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'CS': 1, 'CT': 1}\n",
      "\tdownloading... S2B_34PCS_20210626_0_L2A\n",
      "\tdownloading... S2B_34PCT_20210626_0_L2A\n",
      "\tpatchifying... S2B_34PCS_20210626_0_L2A\n",
      "\t\tskipping... S2B_34PCS_20210626_0_L2A\n",
      "\tpatchifying... S2B_34PCT_20210626_0_L2A\n",
      "./data/labelbox/clouds/temp/collection.json: {'CT': 1, 'CS': 1}\n",
      "\tdownloading... S2B_34PCT_20220919_0_L2A\n",
      "\tdownloading... S2B_34PCS_20220919_0_L2A\n",
      "\tpatchifying... S2B_34PCT_20220919_0_L2A\n",
      "\tpatchifying... S2B_34PCS_20220919_0_L2A\n",
      "\t\tskipping... S2B_34PCS_20220919_0_L2A\n",
      "252 total chips\n",
      "24 chips to add to Labelbox\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "bbox_zakouma = [19.742523, 10.831293, 19.903319, 10.960331]\n",
    "create_new_chips(bbox_zakouma, \"Zakouma\", dates)\n",
    "clean_up()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add old data to new Labelbox flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "old_source_paths = glob.glob('./data/mergedCloudTrainingData/original/source/S2*[0-9].tif')\n",
    "\n",
    "for old_path in old_source_paths:\n",
    "    shutil.copy2(old_path, labelbox_clouds_source_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull labeled data from Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "\n",
    "\n",
    "def get_data_rows():\n",
    "    client = Client(api_key=LABELBOX_API_KEY)\n",
    "    project = client.get_project(CLOUD_PROJECT_ID)\n",
    "    data_rows = project.export_labels(download=True)  \n",
    "    return data_rows\n",
    "\n",
    "\n",
    "def is_island(target_polygon, polygon_list):\n",
    "    for curr_poly in polygon_list:\n",
    "        if target_polygon.within(curr_poly):\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "from common.utilities.imagery import write_array_to_tif\n",
    "\n",
    "\n",
    "CLOUD_CLASSES = {\n",
    "    'no_cloud': 0,\n",
    "    'cloud': 1\n",
    "}\n",
    "\n",
    "data_rows = get_data_rows()\n",
    "data_rows = [dr for dr in data_rows if dr['DataRow Workflow Info']['taskName'] == \"Done\"]\n",
    "print(f'{len(data_rows)} done data rows')\n",
    "\n",
    "for i, row in enumerate(data_rows):\n",
    "        \n",
    "    row_id = row['DataRow ID']\n",
    "    labels = row['Label']['objects']\n",
    "    metadata = json.loads(row['Labeled Data'])\n",
    "    rgb_cog_url = metadata['tileLayerUrl']\n",
    "    file_name = rgb_cog_url.split('/')[-1]\n",
    "    \n",
    "    rgb_path = f'{labelbox_clouds_rgb_dir}/{file_name}'\n",
    "    composite_path = f'{labelbox_clouds_source_dir}/{file_name}'\n",
    "    label_path = f'{labelbox_clouds_labels_dir}/{file_name}'\n",
    "\n",
    "    # TODO: need to handle orphan labels\n",
    "\n",
    "    with rasterio.open(composite_path) as src:\n",
    "        bbox = list(src.bounds)\n",
    "        composite_shape = src.shape\n",
    "        composite_transform = src.transform\n",
    "    \n",
    "    label_polygons = {\n",
    "        label['featureId']: Polygon(label['geometry']['coordinates'][0])\n",
    "        for label in labels\n",
    "    }\n",
    "        \n",
    "    # 0: no_cloud, 1: cloud\n",
    "    labels_data = np.zeros(composite_shape).astype(np.uint8)\n",
    "    \n",
    "    islands = []    \n",
    "    sorted_labels = sorted(labels, key=lambda lab: lab['value'], reverse=True)   \n",
    "    for label in sorted_labels:\n",
    "        class_value = label['value']\n",
    "        class_idx = CLOUD_CLASSES[class_value]\n",
    "                \n",
    "        label_id = label['featureId']\n",
    "        polygon = label_polygons[label_id]\n",
    "        polygon_mask = geometry_mask([polygon], composite_shape, composite_transform, invert=True)\n",
    "        \n",
    "        test_polygons = label_polygons.copy()\n",
    "        del test_polygons[label_id]\n",
    "        is_poly_island = is_island(polygon, list(test_polygons.values()))\n",
    "                \n",
    "        if is_poly_island:\n",
    "            islands.append((class_idx, polygon_mask))\n",
    "        else:\n",
    "            labels_data[polygon_mask] = class_idx\n",
    "\n",
    "    for class_idx, polygon_mask in islands:\n",
    "        labels_data[polygon_mask] = class_idx\n",
    "          \n",
    "    write_array_to_tif(labels_data, label_path, bbox, dtype=np.uint8, nodata=255)\n",
    "       \n",
    "        \n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Geospatial 1.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:081189585635:image/sagemaker-geospatial-v1-0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
