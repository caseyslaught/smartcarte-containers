{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17122ab3-9b89-432f-8d96-2e17017e32c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from common.sagemaker_env import LABELBOX_API_KEY\n",
    "except: \n",
    "    LABELBOX_API_KEY = os.environ['LABELBOX_API_KEY']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad48611-dca8-4138-8709-dedc93b87bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "labelbox_dir = \"./data/labelbox\"\n",
    "clouds_dir = f'{labelbox_dir}/clouds'\n",
    "source_dir = f'{clouds_dir}/source'\n",
    "labels_dir = f'{clouds_dir}/labels'\n",
    "rgb_dir = f'{clouds_dir}/rgb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524df513-954f-4c6b-8e89-b7598bfc7e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def is_island(target_polygon, polygon_list):\n",
    "    for curr_poly in polygon_list:\n",
    "        if target_polygon.within(curr_poly):\n",
    "            return True\n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec813a-c2ad-4d09-a2b0-af6707921d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_35MQV_20200731_0_L2A\n",
      "S2A_35MQV_20200820_0_L2A\n",
      "S2A_35MQU_20211123_0_L2A\n",
      "S2B_35MQU_20211108_0_L2A\n",
      "S2B_35MQU_20211029_0_L2A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16/840083218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mimagery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_array_to_tif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_data_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mimagery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_array_to_tif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNODATA_FLOAT32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/smartcarte-containers/notebooks/src/common/utilities/imagery.py\u001b[0m in \u001b[0;36mwrite_array_to_tif\u001b[0;34m(data, dst_path, bbox, dtype, epsg, nodata, is_cog)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__exit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreceived_exc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuppressed_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;34m\"\"\"Immediately unwind the context stack.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from common.constants import NODATA_BYTE, NODATA_FLOAT32\n",
    "import common.utilities.imagery as imagery\n",
    "import common.utilities.visualization as visualization\n",
    "\n",
    "\n",
    "# normalize_3d_array\n",
    "\n",
    "# 3. upload rgb to S3 and build json for Labelbox\n",
    "# 4. upload to labelbox\n",
    "# 5. pull from labelbox and update labels/\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "scene_dirs = glob.glob(f'./data/20*/S2*')\n",
    "\n",
    "for i, scene_dir in enumerate(scene_dirs):\n",
    "    \n",
    "    scene = scene_dir.split('/')[-1]\n",
    "    print(scene)\n",
    "    \n",
    "    with rasterio.open(f'{scene_dir}/B08.tif') as src:\n",
    "        if src.width < 512 or src.height < 512:\n",
    "            continue\n",
    "    \n",
    "    stack_data = []\n",
    "    transform = None\n",
    "    tif_paths = sorted(glob.glob(f'{scene_dir}/B*.tif'))\n",
    "    for path in tif_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            transform = src.transform\n",
    "            stack_data.append(src.read(1))\n",
    "            \n",
    "    stack_data = np.ma.array(stack_data)\n",
    "    stack_data = imagery.normalize_3d_array(stack_data).transpose((1, 2, 0))\n",
    "        \n",
    "    source_patches = patchify(stack_data, (PATCH_SIZE, PATCH_SIZE, stack_data.shape[2]), step=PATCH_SIZE)\n",
    "    \n",
    "    for irow in range(source_patches.shape[0]):\n",
    "        for icol in range(source_patches.shape[1]):\n",
    "            source_data = source_patches[irow, icol, 0, :, :, :]            \n",
    "            source_data = np.ma.array(source_data, mask=(source_data==NODATA_FLOAT32))\n",
    "            \n",
    "            if source_data.mask.sum() > 0:\n",
    "                print('skipping:', irow, icol)\n",
    "                continue\n",
    "                \n",
    "            #if irow < 3 or icol < 3:\n",
    "            #    continue\n",
    "\n",
    "            rgb_data = source_data[:, :, [2, 1, 0]]\n",
    "            rgb_data_norm = np.round(np.multiply(rgb_data, 254)).astype(int)\n",
    "            rgb_data_norm2 = imagery.normalize_0_254_3d_array(rgb_data)\n",
    "            \n",
    "            #print('\\t', np.min(rgb_data_norm), np.median(rgb_data_norm), np.max(rgb_data_norm))\n",
    "            #print('\\t', np.min(rgb_data_norm2), np.median(rgb_data_norm2), np.max(rgb_data_norm2))\n",
    "            #print('\\t-------------')\n",
    "            \n",
    "            #fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 12))\n",
    "            #visualization.plot_bands(rgb_data1, ax=ax1, bands=[0, 1, 2], transpose=False)\n",
    "            #visualization.plot_bands(rgb_data2, ax=ax2, bands=[0, 1, 2], transpose=False)\n",
    "            #raise\n",
    "                \n",
    "            source_path = f'{source_dir}/{scene}_{irow}_{icol}.tif'\n",
    "            rgb_path = f'{rgb_dir}/{scene}_{irow}_{icol}.tif'\n",
    "                    \n",
    "            x_min, y_min = rasterio.transform.xy(transform, PATCH_SIZE*(irow+1), PATCH_SIZE*icol)\n",
    "            x_max, y_max = rasterio.transform.xy(transform, PATCH_SIZE*irow, PATCH_SIZE*(icol+1))             \n",
    "            bbox = [x_min, y_min, x_max, y_max]\n",
    "            \n",
    "            imagery.write_array_to_tif(rgb_data_norm, rgb_path, bbox, dtype=np.uint8, nodata=255, is_cog=True) \n",
    "            imagery.write_array_to_tif(source_data, source_path, bbox, dtype=np.float32, nodata=NODATA_FLOAT32) \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734588f-1cff-45c5-9b5b-7e124bfae76b",
   "metadata": {},
   "source": [
    "## Create scene patches in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bfb481c-1310-4d3a-8438-a907164ab392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 scenes\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from common.constants import NODATA_BYTE, NODATA_FLOAT32\n",
    "import common.utilities.imagery as imagery\n",
    "import common.utilities.visualization as visualization\n",
    "\n",
    "\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "\n",
    "def process_scene(scene_dir):\n",
    "    \n",
    "    scene = scene_dir.split('/')[-1]\n",
    "    \n",
    "    with rasterio.open(f'{scene_dir}/B08.tif') as src:\n",
    "        if src.width < 512 or src.height < 512:\n",
    "            return\n",
    "\n",
    "    stack_data = []\n",
    "    transform = None\n",
    "    tif_paths = sorted(glob.glob(f'{scene_dir}/B*.tif'))\n",
    "    for path in tif_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            transform = src.transform\n",
    "            stack_data.append(src.read(1))\n",
    "\n",
    "    stack_data = np.ma.array(stack_data)\n",
    "    stack_data = imagery.normalize_3d_array(stack_data).transpose((1, 2, 0))\n",
    "        \n",
    "    source_patches = patchify(stack_data, (PATCH_SIZE, PATCH_SIZE, stack_data.shape[2]), step=PATCH_SIZE)\n",
    "    \n",
    "    for irow in range(source_patches.shape[0]):\n",
    "        for icol in range(source_patches.shape[1]):\n",
    "            source_data = source_patches[irow, icol, 0, :, :, :]            \n",
    "            source_data = np.ma.array(source_data, mask=(source_data==NODATA_FLOAT32))\n",
    "            \n",
    "            if source_data.mask.sum() > 0:\n",
    "                print('skipping:', irow, icol)\n",
    "                continue\n",
    "                \n",
    "            rgb_data = source_data[:, :, [2, 1, 0]]\n",
    "            rgb_data_norm = np.round(np.multiply(rgb_data, 255)).astype(np.uint8) + 1\n",
    "            \n",
    "            source_path = f'{source_dir}/{scene}_{irow}_{icol}.tif'\n",
    "            rgb_path = f'{rgb_dir}/{scene}_{irow}_{icol}.tif'\n",
    "                    \n",
    "            x_min, y_min = rasterio.transform.xy(transform, PATCH_SIZE*(irow+1), PATCH_SIZE*icol)\n",
    "            x_max, y_max = rasterio.transform.xy(transform, PATCH_SIZE*irow, PATCH_SIZE*(icol+1))             \n",
    "            bbox = [x_min, y_min, x_max, y_max]\n",
    "            \n",
    "            imagery.write_array_to_tif(rgb_data_norm, rgb_path, bbox, dtype=np.uint8, nodata=0, is_cog=True) \n",
    "            imagery.write_array_to_tif(source_data, source_path, bbox, dtype=np.float32, nodata=NODATA_FLOAT32) \n",
    "                       \n",
    "            \n",
    "            \n",
    "scene_dirs = glob.glob(f'./data/20*/S2*')\n",
    "print(f'{len(scene_dirs)} scenes')\n",
    "with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    patches = pool.map(process_scene, scene_dirs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc12838c-0196-40be-a293-41f00bd47581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: GTiff/GeoTIFF\n",
      "Files: ./data/labelbox/clouds/rgb/S2A_35MQV_20200731_0_L2A_0_0.tif\n",
      "Size is 512, 512\n",
      "Coordinate System is:\n",
      "GEOGCRS[\"WGS 84\",\n",
      "    DATUM[\"World Geodetic System 1984\",\n",
      "        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n",
      "            LENGTHUNIT[\"metre\",1]]],\n",
      "    PRIMEM[\"Greenwich\",0,\n",
      "        ANGLEUNIT[\"degree\",0.0174532925199433]],\n",
      "    CS[ellipsoidal,2],\n",
      "        AXIS[\"geodetic latitude (Lat)\",north,\n",
      "            ORDER[1],\n",
      "            ANGLEUNIT[\"degree\",0.0174532925199433]],\n",
      "        AXIS[\"geodetic longitude (Lon)\",east,\n",
      "            ORDER[2],\n",
      "            ANGLEUNIT[\"degree\",0.0174532925199433]],\n",
      "    ID[\"EPSG\",4326]]\n",
      "Data axis to CRS axis mapping: 2,1\n",
      "Origin = (29.242784885946573,-0.591630233123690)\n",
      "Pixel Size = (0.000089771893148,-0.000090466247379)\n",
      "Metadata:\n",
      "  AREA_OR_POINT=Area\n",
      "Image Structure Metadata:\n",
      "  INTERLEAVE=PIXEL\n",
      "  LAYOUT=COG\n",
      "Corner Coordinates:\n",
      "Upper Left  (  29.2427849,  -0.5916302) ( 29d14'34.03\"E,  0d35'29.87\"S)\n",
      "Lower Left  (  29.2427849,  -0.6379490) ( 29d14'34.03\"E,  0d38'16.62\"S)\n",
      "Upper Right (  29.2887481,  -0.5916302) ( 29d17'19.49\"E,  0d35'29.87\"S)\n",
      "Lower Right (  29.2887481,  -0.6379490) ( 29d17'19.49\"E,  0d38'16.62\"S)\n",
      "Center      (  29.2657665,  -0.6147896) ( 29d15'56.76\"E,  0d36'53.24\"S)\n",
      "Band 1 Block=512x512 Type=Byte, ColorInterp=Red\n",
      "  Minimum=0.000, Maximum=254.000, Mean=53.907, StdDev=50.988\n",
      "  NoData Value=255\n",
      "  Metadata:\n",
      "    STATISTICS_MAXIMUM=254\n",
      "    STATISTICS_MEAN=53.906730651855\n",
      "    STATISTICS_MINIMUM=0\n",
      "    STATISTICS_STDDEV=50.988056638052\n",
      "    STATISTICS_VALID_PERCENT=100\n",
      "Band 2 Block=512x512 Type=Byte, ColorInterp=Green\n",
      "  Minimum=0.000, Maximum=254.000, Mean=52.718, StdDev=46.561\n",
      "  NoData Value=255\n",
      "  Metadata:\n",
      "    STATISTICS_MAXIMUM=254\n",
      "    STATISTICS_MEAN=52.717845916748\n",
      "    STATISTICS_MINIMUM=0\n",
      "    STATISTICS_STDDEV=46.561163657992\n",
      "    STATISTICS_VALID_PERCENT=100\n",
      "Band 3 Block=512x512 Type=Byte, ColorInterp=Blue\n",
      "  Minimum=0.000, Maximum=254.000, Mean=32.018, StdDev=46.706\n",
      "  NoData Value=255\n",
      "  Metadata:\n",
      "    STATISTICS_MAXIMUM=254\n",
      "    STATISTICS_MEAN=32.017772674561\n",
      "    STATISTICS_MINIMUM=0\n",
      "    STATISTICS_STDDEV=46.706124925424\n",
      "    STATISTICS_VALID_PERCENT=100\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gdalinfo -stats ./data/labelbox/clouds/rgb/S2A_35MQV_20200731_0_L2A_0_0.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe10813-9fc8-4c4b-a72c-55f59e30a670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import common.constants as constants\n",
    "import common.aws.s3 as s3_utils\n",
    "\n",
    "\n",
    "def save_patch_to_s3(tif_path):\n",
    "    \n",
    "    file_name = tif_path.split('/')[-1]    \n",
    "    object_key = f'clouds/{file_name}'\n",
    "    href = f'https://data.smartcarte.earth/{object_key}'\n",
    "    # print(f'uploading {tif_path} to s3://{constants.S3_DATA_BUCKET}/{object_key}')\n",
    "    s3_utils.put_item(tif_path, constants.S3_DATA_BUCKET, object_key)\n",
    "    \n",
    "    return href\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5704a02d-15b2-427a-b183-37f1c6379fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632 paths\n",
      "0 done\n",
      "200 done\n",
      "400 done\n",
      "600 done\n",
      "800 done\n",
      "1000 done\n",
      "1200 done\n",
      "1400 done\n",
      "1600 done\n",
      "1800 done\n",
      "2000 done\n",
      "2200 done\n",
      "2400 done\n",
      "2600 done\n",
      "2800 done\n",
      "3000 done\n",
      "3200 done\n",
      "3400 done\n",
      "3600 done\n"
     ]
    }
   ],
   "source": [
    "import shelve\n",
    "\n",
    "\n",
    "state_path = \"./data/trainCloudsState\"\n",
    "with shelve.open(state_path) as state:\n",
    "\n",
    "    rgb_paths = glob.glob(f'{rgb_dir}/*.tif')\n",
    "    print(f'{len(rgb_paths)} paths')\n",
    "    for i, path in enumerate(rgb_paths):\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(f'{i} done')\n",
    "            \n",
    "        job_name = path.split('/')[-1].replace('.tif', '')\n",
    "        s3_href = save_patch_to_s3(path)\n",
    "        state[job_name] = {\n",
    "            'rgb_cog_href': s3_href\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3360acef-f0e3-4f5d-8a9f-3465878ddc32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 data rows\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "from labelbox import Client, Dataset, DataRow\n",
    "import os\n",
    "import random\n",
    "import shelve\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "client = Client(api_key=LABELBOX_API_KEY)\n",
    "project = client.get_project(\"cleamnf3q398707ug5s2z4rp6\")\n",
    "\n",
    "today = datetime.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "clouds_dataset_name = f\"{today} Clouds\"\n",
    "\n",
    "clouds_dataset = client.get_datasets(where=(Dataset.name==clouds_dataset_name)).get_one()\n",
    "if clouds_dataset is None:\n",
    "    clouds_dataset = client.create_dataset(name=clouds_dataset_name)\n",
    "else:\n",
    "    raise ValueError(\"today's clouds dataset already exists\")\n",
    "\n",
    "    \n",
    "payload = []\n",
    "with shelve.open(state_path) as state:\n",
    "    for job_name in state.keys():        \n",
    "        row = {\n",
    "            \"min_zoom\": 12,\n",
    "            \"max_zoom\": 14,\n",
    "            \"tile_layer_url\": state[job_name][\"rgb_cog_href\"]\n",
    "        }\n",
    "        \n",
    "        payload.append(row)\n",
    "\n",
    "\n",
    "payload = [{DataRow.row_data: row} for row in payload]\n",
    "\n",
    "random.seed(666)\n",
    "random.shuffle(payload)\n",
    "\n",
    "start_idx, end_idx = 0, 1000\n",
    "payload = payload[start_idx:end_idx]\n",
    "\n",
    "print(f'{len(payload)} data rows')\n",
    "task = clouds_dataset.create_data_rows(payload)\n",
    "task.wait_till_done()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359cea1-9d95-401f-8b53-9d062bad39db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"./data/labelbox/clouds/source/*.tif\")\n",
    "print(len(files))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Geospatial 1.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:081189585635:image/sagemaker-geospatial-v1-0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
