{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0222063-5eef-400e-aba8-aa4a2e05f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\casey\\Work\\SmartCarteContainers\\notebooks\\venvnn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66bb715-cc3b-4d41-a6c0-43aca3e7cdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0009)\n",
      "0.0008645428461022675\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "\n",
    "z = x.mul(y)\n",
    "\n",
    "val = z[0, 1]\n",
    "print(val)\n",
    "print(val.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a2d843-8957-4dc6-8569-b55503944f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5774],\n",
      "        [0.0023],\n",
      "        [0.8425],\n",
      "        [0.6044]])\n"
     ]
    }
   ],
   "source": [
    "# reshaping\n",
    "view = x.view(4, 1)\n",
    "print(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde95485-2df0-4b34-8b04-b11dbfd2eb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4337, 0.7251, 0.6140, 0.8373, 0.4396])\n",
      "[0.43366426 0.7251383  0.6139728  0.83731425 0.43959004]\n",
      "tensor([1.4337, 1.7251, 1.6140, 1.8373, 1.4396])\n",
      "[1.4336643 1.7251383 1.6139728 1.8373142 1.43959  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# change one will change the other if both on CPU (not GPU)\n",
    "\n",
    "a = torch.rand(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1aad3ec-8324-4d4f-9b8a-a6397cf03f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you have a GPU available\n",
    "# this isn't possible with Windows and ROCm (only Linux)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"hey\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device=device)\n",
    "    y = torch.rand(5)\n",
    "    y = y.to(device)\n",
    "    z = x + y\n",
    "    # z.numpy() ...causes an error\n",
    "    z = z.to(\"cpu\")\n",
    "    z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d107d62-36ce-434a-b785-f2a4494863a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0532, 0.4881, 0.3649], requires_grad=True)\n",
      "tensor([2.0532, 2.4881, 2.3649], grad_fn=<AddBackward0>)\n",
      "tensor([ 8.4309, 12.3811, 11.1856], grad_fn=<MulBackward0>)\n",
      "tensor(10.6659, grad_fn=<MeanBackward0>)\n",
      "tensor([2.7375, 3.3174, 3.1532])\n"
     ]
    }
   ],
   "source": [
    "# autograd\n",
    "\n",
    "x = torch.rand(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2 # <AddBackward>\n",
    "print(y)\n",
    "\n",
    "z = y * y * 2 # <MulBackward>\n",
    "print(z)\n",
    "\n",
    "z = z.mean() # <MeanBackward>\n",
    "print(z)\n",
    "# v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "\n",
    "z.backward() # can only be created for scalar inputs (i.e. one value), otherwise pass v to backward\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680ecf10-8290-4e3a-b080-84bbf01141e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [00:01<00:00, 55.58it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:01<00:00, 54.22it/s]\n",
      "Restoring states from the checkpoint path at c:\\Users\\casey\\Work\\SmartCarteContainers\\notebooks\\src\\.lr_find_748e9133-09a8-4809-97f0-66d02d6411fd.ckpt\n",
      "Restored all states from the checkpoint file at c:\\Users\\casey\\Work\\SmartCarteContainers\\notebooks\\src\\.lr_find_748e9133-09a8-4809-97f0-66d02d6411fd.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_lr:  0.003981071705534969\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Lightning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "input_size = 784 # 28x28 I think the input size must be the same! Bboxes must be same size.\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "class NeuralNet(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # self.l0 = nn.Conv3d(4, 4, 10) can do cool stuff like this\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # weights are randomly initialized\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = self.forward(images)\n",
    "        # outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        \n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   num_workers=4,\n",
    "                                                   shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   num_workers=4,\n",
    "                                                   shuffle=False)\n",
    "        return test_loader\n",
    "    \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        \n",
    "        tensorboard_logs = {'avg_val_loss': avg_loss}\n",
    "        \n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(fast_dev_run=False, max_epochs=num_epochs) # gpus=1, auto_lr_find=True\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "lr_find_result = trainer.tuner.lr_find(model, \n",
    "                                       early_stop_threshold=None,\n",
    "                                       train_dataloaders=model.train_dataloader(), \n",
    "                                       val_dataloaders=model.val_dataloader())\n",
    "new_lr = lr_find_result.suggestion()\n",
    "print('new_lr: ', new_lr)\n",
    "model.learning_rate = new_lr\n",
    "trainer.fit(model, train_dataloaders=model.train_dataloader(), val_dataloaders=model.val_dataloader())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff7e871-2c74-4a3a-b507-9a3a052ae704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c4ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/lang/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from common.constants import NODATA_FLOAT32\n",
    "\n",
    "\n",
    "torch.manual_seed(666)\n",
    "\n",
    "\n",
    "class LabeledS2Dataset(Dataset):\n",
    "    def __init__(self, root_dir, sub_dir):\n",
    "        self.data_dir = f'{root_dir}/{sub_dir}'\n",
    "        self.image_paths = glob.glob(f'{self.data_dir}/images/*.tif')\n",
    "        self.label_paths = glob.glob(f'{self.data_dir}/labels/*.tif')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_path = self.image_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read()\n",
    "            image[image == NODATA_FLOAT32] = -0.01\n",
    "            # handle nodata here...\n",
    "            image = torch.from_numpy(image)\n",
    "\n",
    "        with rasterio.open(label_path) as src:\n",
    "            label = src.read()\n",
    "            label = torch.from_numpy(label).long()\n",
    "\n",
    "        return image, label    \n",
    "    \n",
    "\n",
    "train_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=0, shuffle=True)\n",
    "\n",
    "test_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='test')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=0, shuffle=True)\n",
    "\n",
    "val_dataset = LabeledS2Dataset(root_dir='./data/trainingData', sub_dir='val')\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2be969-f742-4b9c-851a-1bd777252d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.utils as smp_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "CLASSES = {\n",
    "    'unclassified': 0,\n",
    "    'agriculture': 1,\n",
    "    'bare_dark': 2,\n",
    "    'bare_light': 3,\n",
    "    'built': 4,\n",
    "    'burn': 5,\n",
    "    'cloud': 6,\n",
    "    'flooded_vegetation': 7,\n",
    "    'grass_dry': 8,\n",
    "    'grass_verdant': 9,\n",
    "    'shrubs': 10,\n",
    "    'trees': 11,\n",
    "    'water': 12,   \n",
    "}\n",
    "\n",
    "CLASS_NAMES = list(CLASSES.keys())\n",
    "CLASS_INDEXES = list(CLASSES.values())\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name='resnet18', \n",
    "    encoder_depth=5, \n",
    "    encoder_weights='imagenet', \n",
    "    decoder_use_batchnorm=True, \n",
    "    decoder_channels=(256, 128, 64, 32, 16), \n",
    "    decoder_attention_type=None, \n",
    "    in_channels=4, \n",
    "    classes=len(CLASS_NAMES), \n",
    "    activation=None, \n",
    "    aux_params=None\n",
    ")\n",
    "\n",
    "\n",
    "loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "loss.__name__ = 'Dice_loss'\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "metrics = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9253b40-6efe-4612-bde9-abf7acb4b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_epoch = smp_utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics= metrics,\n",
    "    optimizer=optimizer,\n",
    "    #device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "test_epoch = smp_utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    #device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4839f1-cbac-4807-bcec-5c142f5de173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 24/24 [07:38<00:00, 19.11s/it, Dice_loss - 0.2476]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      4\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m train_epoch\u001b[38;5;241m.\u001b[39mrun(train_dataloader)\n\u001b[0;32m----> 5\u001b[0m     test_logs \u001b[38;5;241m=\u001b[39m test_epoch\u001b[38;5;241m.\u001b[39mrun(\u001b[43mtest_dataloader\u001b[49m)\n\u001b[1;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./best_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "\n",
    "for i in range(0, 2):\n",
    "    train_logs = train_epoch.run(train_dataloader)\n",
    "    test_logs = test_epoch.run(test_dataloader)\n",
    "    torch.save(model, './best_model.pth')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8202375682d73a89481dfa5a8a17ecb8611f14e3b3346f4ac74d3d09f0e43363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
